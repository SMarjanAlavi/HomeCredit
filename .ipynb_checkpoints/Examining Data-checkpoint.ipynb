{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Credit Risk Default: Examining Data\n",
    "## <font face=\"times\" color = \"#990000\"> Introduction: </font>\n",
    "A financing institute have received several loan request applications. They want to find qualified applicants to receive the loan. Unfortunately, there is no credit history available for the applicants. However, they have historical data available from previous applicants. This program aims to predict which applicant will repay the loan and which one will not.\n",
    "\n",
    "The data is downloaded from a kaggle competition. You can find more information at https://www.kaggle.com/c/home-credit-default-risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font face=\"times\" color = \"#990000\"> Reading the data: </font>\n",
    "First of all, we need to look at the data. In this project, I have downloaded the training and test sets <a href=\"https://en.wikipedia.org/wiki/Training,_test,_and_validation_sets\">(What are training/test sets?!)</a> from the API provided by <a href=\"https://www.kaggle.com/c/home-credit-default-risk/data\">\n",
    "Kaggle </a>. We assume you have saved the data ('application_train.csv' and 'application_test.csv' files) in a folder name \"Data\". The \"Data\" folder is located in the same folder as your python file is (in this example, homecredit folder). \n",
    "\n",
    "Since the extention of the data is .csv, you need to read it using <font face=\"courier new\" color = \"#990000\">pd.read_csv</font> as shown bellow. Here, <font face=\"courier new\" color = \"#990000\">'pd'</font> is a name we use to call pandas library, and <font face=\"courier new\" color = \"#990000\">'read_cv'</font> is an attribute of pandas library. Before we use any of the pandas attributes, we have to import the library using <font face=\"courier new\" color = \"#990000\">'import'</font>. The training data is read and saved in a dataframe which we name <font face=\"courier new\" color = \"#009933\">'df_train'</font>. Similarly, the training set is read and saved in a dataframe which we name <font face=\"courier new\" color = \"#009933\">'df_test'</font>.\n",
    "\n",
    "You can also call the file by using its complete path address, e.g., <font face=\"courier new\" color = \"#990000\">'C:/Users/marjan/homecredit/Data/application_train.csv'</font>. \n",
    "\n",
    "Now, you san run the bellow cell by selecting it and pressing \"Shift\"+\"Enter\". You will notice that the number beside cell will be changed into * which indicates the cell is running. It may take a few seconds or more for the data to be read depending on the size of the data. When the star sign changes into a number, the file is read. You will not see any output here unless an error exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'Data/application_train.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4b54f1d209a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data/application_train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#df_test = pd.read_csv('Data/application_test.csv')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alavimar\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alavimar\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alavimar\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alavimar\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alavimar\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'Data/application_train.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv('Data/application_train.csv')\n",
    "#df_test = pd.read_csv('Data/application_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font face=\"times\" color = \"#990000\"> Examining the data: </font>\n",
    "It is good to know how big as your dataset and how many rows and columns it has. <font face=\"courier new\" color = \"#990000\">'shape'</font> is the attribute that shows the number of rows and columns of your dataframe. \n",
    "You can find the number of rows of a dataframe by adding <font face=\"courier new\" color = \"#990000\">'.shape[0]'</font> to the dataframe's name.\n",
    "Similarly, the number of columns can be found by adding <font face=\"courier new\" color = \"#990000\">'.shape[1]'</font> to the dataframe's name.\n",
    "Inorder to see the results, you need to print them using the <font face=\"courier new\" color = \"#990000\">'print'</font> instruction. In python 3, you have to used parantheses, and type whatever you want to print inside a pair of paranthesis. Use quotation marks (single or double) to print an exact srting, and use the name of variables without quotation marks to print the value of the vaiables. Seperate them using commas. \n",
    "Rune the bellow cell to see the output of the print line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_rows_train = df_train.shape[0]\n",
    "number_of_columns_train = df_train.shape[1]\n",
    "print('The training data has', number_of_rows_train, 'rows, and', number_of_columns_train, 'columns.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font face=\"times\" color = \"#990000\"> Displaying a few rows of the data: </font>\n",
    "As you can see, the training set has 307511 rows which is a lot! It is a good idea to look at the few first row of the dataset to have an idea of how it looks like. the <font face=\"courier new\" color = \"#990000\">'head()'</font> attribute, select only the first five rows of the data. You can determine the number of first rows you want to select by adding a number inside paranthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be interesting to know that the last rows of a data fram can be selected by the <font face=\"courier new\" color = \"#990000\">'.tail()'</font> attribute. The line bellow select the last three rows of the training set data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font face=\"times\" color = \"#990000\"> Statistical Description of the data: </font>\n",
    "Finally, to have a statistic description of your data set, you can use <font face=\"courier new\" color = \"#990000\">'.describe()'</font> attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('A statistical description of the training data: \\n', df_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, a dataframe with 8 rows and 106 columns appear. You might have noticed that the number of columns are 106 here, while in the dataset, we had 122 columns. It is because we have only 106 numerical data columns, which are considered in the describe method. We have 122-106=16 columns with non-numeric type in the training datase which are ignored here.  \n",
    "\n",
    "### <font face=\"courier new\" color = \"#6600cc\">count:</font> \n",
    "The first row shows the number of data in each column. For example, the number of data in the last column (AMT_REQ_CREDIT_BUREAU_YEAR) is 265992, while the number of data in the first column is 307511. It shows that we have some missed data in the dataframe.\n",
    "\n",
    "### <font face=\"courier new\" color = \"#6600cc\">mean:</font>\n",
    "It shows the average value of each column \n",
    "\n",
    "### <font face=\"courier new\" color = \"#6600cc\">std:</font> \n",
    "It shows the standard deviation of the value of each column. A near zero std shows a quite constant data in the given column.\n",
    "\n",
    "### <font face=\"courier new\" color = \"#6600cc\">min:</font> \n",
    "It shows the minimum value of each column\n",
    "\n",
    "### <font face=\"courier new\" color = \"#6600cc\">25%, 50%, and 75%:</font>\n",
    "It shows the 25% value of each column. One-forth of the data from that column have a value less than this. For example,  the 25% value of the first column is 189145.5. It indicates in the first column from all 307511 rows, 76878 rows have a value less than 189145.5, and 230633 rows have a value more than 189145.5. 50% and 75% gives us statistical distribution information from each column similar to the 25%.\n",
    "\n",
    "### <font face=\"courier new\" color = \"#6600cc\">max:</font>\n",
    "It shows the maximum value of each column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set shows our historical data including the information from the applicants, and weather they had repaid the loan or not. In order to use the training set, we have to know the name of the columns and where to find required data. The list of the name of the columns can be found using <font face=\"courier new\" color = \"#990000\">'.columns'</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_number = 0\n",
    "for i in df_train.columns:\n",
    "    print(column_number,i)\n",
    "    column_number = column_number + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column is the application ID which is a unique identifier for each applicant. The second column, shows the target. If the target is equal to 1 it shows the applicant did not return the loan. \n",
    "Using the <font face=\"courier new\" color = \"#990000\">'.count()'</font> attribute, we can find the number of applications we have in the training set. In order to efer to a specific column from the dataset, we should write the column name in the quotation marks inside brakets infront of the dataframe's name. Note that python is a case sensitive language. So, to call the column name properly, you need to consider the lower or upper case letters as it appears in the column list. After the column is indicated, we can add the attribute to find the number of unique applicants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are', df_train['SK_ID_CURR'].count(), 'unique loan applicants in total.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font face=\"times\" color = \"#990000\"> Imbalance Training Set: </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we apply any machine learning algorithm to predict the target of the test set, we need to see if the training set is balanced or not. If the training set is imbalance, the prediction quality drops significantly. In most of the cases like in this project, the training set is imbalanced; we have more information about the applicants who have returned their loan, and we have only few examples of the applicants who did not repaid their loan. So, if we work with this imbalance set, the prediction behaves better of the applicants with TARGET = 0, and it will face problems (higher error) on determining the applicants who will not repay their loan.\n",
    "\n",
    "So, the first task is to find how imbalance our training set is. To find the number of Targets, we can use <font face=\"courier new\" color = \"#990000\">'.sum()'</font> attribute. Note that we cannot use the <font face=\"courier new\" color = \"#990000\">'.count()'</font> attribute here, because it will count both zeros and ones in the TARGET column.\n",
    "The difference between the number of tatal rows in the TARGET column and the number of the TARGETS with the value of one, gives us the number of non-target samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_targets = df_train[\"TARGET\"].sum()\n",
    "number_of_samples = df_train['SK_ID_CURR'].count()\n",
    "number_of_non_targets = number_of_samples - number_of_targets\n",
    "balance_ratio = number_of_targets / number_of_samples * 100\n",
    "print('We have', number_of_samples, 'samples;', number_of_targets,'of them with TARGETS = 1, and ',\\\n",
    "      number_of_non_targets, 'with TARGET= 0. So, only %.1f'%balance_ratio, '% of samples are targets.' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font face=\"times\" color = \"#990000\"> Ehat is Next? </font>\n",
    "Up to know, we read the data, and examine it. in the next part, we deal with unbalance data and try to find a balance between TARGETs and non-Target Samples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
